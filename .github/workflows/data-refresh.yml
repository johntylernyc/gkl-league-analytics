name: Scheduled Data Refresh

on:
  # Allow manual trigger with inputs
  workflow_dispatch:
    inputs:
      refresh_type:
        description: 'Type of refresh (morning/afternoon/night/manual)'
        required: true
        default: 'manual'
        type: choice
        options:
          - morning
          - afternoon
          - night
          - manual
      environment:
        description: 'Environment to run in'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - test
      date_range:
        description: 'Date range (start,end in YYYY-MM-DD format)'
        required: false
        type: string
  
  # Scheduled runs (backup in case CloudFlare Worker fails)
  schedule:
    # Run at 6:05 AM, 1:05 PM, and 10:05 PM ET (5 minutes after CloudFlare)
    - cron: '5 10 * * *'   # 6:05 AM ET (EST)
    - cron: '5 17 * * *'   # 1:05 PM ET (EST)
    - cron: '5 2 * * *'    # 10:05 PM ET (EST, runs at 2:05 AM UTC next day)

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '20'

jobs:
  determine-refresh-params:
    name: Determine Refresh Parameters
    runs-on: ubuntu-latest
    outputs:
      refresh_type: ${{ steps.params.outputs.refresh_type }}
      start_date: ${{ steps.params.outputs.start_date }}
      end_date: ${{ steps.params.outputs.end_date }}
      environment: ${{ steps.params.outputs.environment }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Determine parameters
        id: params
        run: |
          # Get current time in ET
          export TZ='America/New_York'
          CURRENT_HOUR=$(date +%H)
          TODAY=$(date +%Y-%m-%d)
          
          # Determine refresh type if not manually specified
          if [ "${{ github.event_name }}" == "schedule" ]; then
            if [ "$CURRENT_HOUR" -eq 6 ]; then
              REFRESH_TYPE="morning"
            elif [ "$CURRENT_HOUR" -eq 13 ]; then
              REFRESH_TYPE="afternoon"
            elif [ "$CURRENT_HOUR" -eq 22 ]; then
              REFRESH_TYPE="night"
            else
              REFRESH_TYPE="adhoc"
            fi
          else
            REFRESH_TYPE="${{ github.event.inputs.refresh_type || 'manual' }}"
          fi
          
          # Determine date range
          if [ -n "${{ github.event.inputs.date_range }}" ]; then
            IFS=',' read -r START_DATE END_DATE <<< "${{ github.event.inputs.date_range }}"
          else
            case $REFRESH_TYPE in
              morning)
                # Full refresh: 7 days for stat corrections
                START_DATE=$(date -d "7 days ago" +%Y-%m-%d)
                END_DATE=$TODAY
                ;;
              afternoon|night)
                # Incremental: 3 days for lineup changes
                START_DATE=$(date -d "3 days ago" +%Y-%m-%d)
                END_DATE=$TODAY
                ;;
              *)
                # Default: 7 days for manual runs to catch up on data
                START_DATE=$(date -d "7 days ago" +%Y-%m-%d)
                END_DATE=$TODAY
                ;;
            esac
          fi
          
          # Determine environment
          ENVIRONMENT="${{ github.event.inputs.environment || 'production' }}"
          
          # Output parameters
          echo "refresh_type=$REFRESH_TYPE" >> $GITHUB_OUTPUT
          echo "start_date=$START_DATE" >> $GITHUB_OUTPUT
          echo "end_date=$END_DATE" >> $GITHUB_OUTPUT
          echo "environment=$ENVIRONMENT" >> $GITHUB_OUTPUT
          
          # Log parameters
          echo "Refresh Type: $REFRESH_TYPE"
          echo "Date Range: $START_DATE to $END_DATE"
          echo "Environment: $ENVIRONMENT"

  refresh-transactions:
    name: Refresh Transactions
    needs: determine-refresh-params
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests python-dotenv
      
      - name: Run transaction incremental update  
        env:
          YAHOO_CLIENT_ID: ${{ secrets.YAHOO_CLIENT_ID }}
          YAHOO_CLIENT_SECRET: ${{ secrets.YAHOO_CLIENT_SECRET }}
          YAHOO_REDIRECT_URI: ${{ secrets.YAHOO_REDIRECT_URI }}
          YAHOO_REFRESH_TOKEN: ${{ secrets.YAHOO_REFRESH_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          D1_DATABASE_ID: ${{ secrets.D1_DATABASE_ID }}
        run: |
          echo "Running transaction incremental update with D1 direct write..."
          # Calculate days between start and end date
          START_DATE="${{ needs.determine-refresh-params.outputs.start_date }}"
          END_DATE="${{ needs.determine-refresh-params.outputs.end_date }}"
          DAYS=$((( $(date -d "$END_DATE" +%s) - $(date -d "$START_DATE" +%s) ) / 86400 + 1))
          
          python data_pipeline/league_transactions/update_transactions.py \
            --days $DAYS \
            --environment ${{ needs.determine-refresh-params.outputs.environment }} \
            --use-d1
          
          # Check exit code and fail the job if the script failed
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            echo "Transaction update failed with exit code $EXIT_CODE"
            exit $EXIT_CODE
          fi
      
      - name: Debug output
        if: always()
        run: |
          echo "Transaction job completed"
          echo "Working directory contents:"
          ls -la

  refresh-lineups:
    name: Refresh Daily Lineups
    needs: determine-refresh-params
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests python-dotenv
      
      - name: Run lineup incremental update
        env:
          YAHOO_CLIENT_ID: ${{ secrets.YAHOO_CLIENT_ID }}
          YAHOO_CLIENT_SECRET: ${{ secrets.YAHOO_CLIENT_SECRET }}
          YAHOO_REDIRECT_URI: ${{ secrets.YAHOO_REDIRECT_URI }}
          YAHOO_REFRESH_TOKEN: ${{ secrets.YAHOO_REFRESH_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          D1_DATABASE_ID: ${{ secrets.D1_DATABASE_ID }}
        run: |
          echo "Running lineup incremental update with D1 direct write..."
          # Calculate days between start and end date
          START_DATE="${{ needs.determine-refresh-params.outputs.start_date }}"
          END_DATE="${{ needs.determine-refresh-params.outputs.end_date }}"
          DAYS=$((( $(date -d "$END_DATE" +%s) - $(date -d "$START_DATE" +%s) ) / 86400 + 1))
          
          python data_pipeline/daily_lineups/update_lineups.py \
            --days $DAYS \
            --environment ${{ needs.determine-refresh-params.outputs.environment }} \
            --use-d1
          
          # Check exit code and fail the job if the script failed
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            echo "Lineup update failed with exit code $EXIT_CODE"
            exit $EXIT_CODE
          fi
      
      - name: Debug output
        if: always()
        run: |
          echo "Lineup job completed"
          echo "Working directory contents:"
          ls -la

# Player stats refresh enabled for comprehensive MLB player statistics
  refresh-stats:
    name: Refresh Player Stats
    needs: determine-refresh-params  # Only depends on params, runs in parallel with others
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests python-dotenv pybaseball pandas
      
      - name: Initialize player mappings in local database
        run: |
          echo "Initializing player mappings in local SQLite database..."
          python -c "
import sys
sys.path.append('.')
from data_pipeline.player_stats.comprehensive_collector import ComprehensiveStatsCollector
collector = ComprehensiveStatsCollector(environment='production', use_d1=False)
import sqlite3
conn = sqlite3.connect('database/league_analytics.db')
cursor = conn.cursor()
cursor.execute('SELECT COUNT(*) FROM player_mapping')
count = cursor.fetchone()[0]
if count == 0:
    print('No player mappings found, initializing...')
    collector.initialize_player_mappings()
    cursor.execute('SELECT COUNT(*) FROM player_mapping')
    new_count = cursor.fetchone()[0]
    print(f'Initialized {new_count} player mappings')
else:
    print(f'Found {count} existing player mappings')
conn.close()
"
      
      - name: Sync player mappings to D1
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          D1_DATABASE_ID: ${{ secrets.D1_DATABASE_ID }}
        run: |
          echo "Syncing player mappings to D1..."
          python data_pipeline/player_stats/sync_player_mappings_to_d1.py --environment production || true
      
      - name: Run stats incremental update
        env:
          YAHOO_CLIENT_ID: ${{ secrets.YAHOO_CLIENT_ID }}
          YAHOO_CLIENT_SECRET: ${{ secrets.YAHOO_CLIENT_SECRET }}
          YAHOO_REDIRECT_URI: ${{ secrets.YAHOO_REDIRECT_URI }}
          YAHOO_REFRESH_TOKEN: ${{ secrets.YAHOO_REFRESH_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          D1_DATABASE_ID: ${{ secrets.D1_DATABASE_ID }}
        run: |
          echo "Running stats incremental update with D1 direct write..."
          # Calculate days between start and end date
          START_DATE="${{ needs.determine-refresh-params.outputs.start_date }}"
          END_DATE="${{ needs.determine-refresh-params.outputs.end_date }}"
          DAYS=$((( $(date -d "$END_DATE" +%s) - $(date -d "$START_DATE" +%s) ) / 86400 + 1))
          echo "Collecting stats for $DAYS days from $START_DATE to $END_DATE"
          
          python data_pipeline/player_stats/update_stats.py \
            --days $DAYS \
            --environment ${{ needs.determine-refresh-params.outputs.environment }} \
            --use-d1
          
          # Check exit code and fail the job if the script failed
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            echo "Stats update failed with exit code $EXIT_CODE"
            exit $EXIT_CODE
          fi

# Sync to CloudFlare job removed - using direct D1 writes instead
# This eliminates the two-step process (Local SQLite → Export → D1)
# in favor of single-step GitHub Actions → D1 direct writes

  notify-completion:
    name: Send Notifications  
    needs: [determine-refresh-params, refresh-transactions, refresh-lineups, refresh-stats]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: Determine status
        id: status
        run: |
          if [ "${{ needs.refresh-transactions.result }}" == "success" ] && \
             [ "${{ needs.refresh-lineups.result }}" == "success" ] && \
             [ "${{ needs.refresh-stats.result }}" == "success" ]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "message=✅ D1 data refresh completed successfully (transactions, lineups, and player stats)" >> $GITHUB_OUTPUT
          else
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "message=❌ D1 data refresh failed" >> $GITHUB_OUTPUT
          fi
      
      - name: Send Slack notification
        if: vars.SLACK_WEBHOOK_URL != ''
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ steps.status.outputs.status }}
          text: |
            ${{ steps.status.outputs.message }}
            Refresh Type: ${{ needs.determine-refresh-params.outputs.refresh_type }}
            Date Range: ${{ needs.determine-refresh-params.outputs.start_date }} to ${{ needs.determine-refresh-params.outputs.end_date }}
            Environment: ${{ needs.determine-refresh-params.outputs.environment }}
          webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}
      
      - name: Send Discord notification
        if: vars.DISCORD_WEBHOOK_URL != ''
        env:
          DISCORD_WEBHOOK: ${{ secrets.DISCORD_WEBHOOK_URL }}
        run: |
          STATUS="${{ steps.status.outputs.status }}"
          if [ "$STATUS" == "success" ]; then
            COLOR="3066993"
          else
            COLOR="15158332"
          fi
          
          curl -H "Content-Type: application/json" \
            -X POST \
            -d "{
              \"embeds\": [{
                \"title\": \"Data Refresh Complete\",
                \"description\": \"${{ steps.status.outputs.message }}\",
                \"color\": $COLOR,
                \"fields\": [
                  {
                    \"name\": \"Refresh Type\",
                    \"value\": \"${{ needs.determine-refresh-params.outputs.refresh_type }}\",
                    \"inline\": true
                  },
                  {
                    \"name\": \"Environment\",
                    \"value\": \"${{ needs.determine-refresh-params.outputs.environment }}\",
                    \"inline\": true
                  },
                  {
                    \"name\": \"Date Range\",
                    \"value\": \"${{ needs.determine-refresh-params.outputs.start_date }} to ${{ needs.determine-refresh-params.outputs.end_date }}\",
                    \"inline\": false
                  }
                ],
                \"footer\": {
                  \"text\": \"GKL Fantasy Analytics\"
                },
                \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"
              }]
            }" \
            $DISCORD_WEBHOOK